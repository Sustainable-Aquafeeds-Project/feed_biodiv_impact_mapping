---
title: "Tidying data"
author: "Gage Clawson"
date: "05/02/2023"
output: html_document
---

## Summary

This script preps necessary data used in subsequent scripts. 

 - preps mapspam rasters
 - preps FAOSTAT aquaculture data
 - preps FAOSTAT crop production data
 - create a base spatial raster 
 - download IUCN threats of interest to feeds
 - prep Watson fisheries catch data 
 - download and prep forage fish species lists
 - filter Watson spatialised catch data for forage fish species so it can be stored in the project

```{r}
library(tidyverse)
library(parallel)
library(janitor)
library(here)
library(countrycode)
library(rredlist)
library(terra)
library(raster)

source(here("src/directories.R"))
source(here("src/spatial.R"))

fishstat_dir <- file.path(rdsi_raw_data_dir, "fao/FAO_fishstat_2020")
```


This is the code to unzip and adjust the extents of the mapspam rasters (-180, 180, -90, 90) - DO NOT RUN IN PROJECT - here as a backup to scripts in the raw data files

```{r}


mapspam_zip_files <- list.files(path = mapspam_dir, pattern = "\\.zip$")


lapply(X=mapspam_zip_files, FUN = unzip)


#Adjust the extent of rasters to full lon lat coveragge

#test
banana <- raster(file.path(mapspam_dir, "spam2010V2r0_global_H_BANA_H.tif"))
banana

#this should be the new extent for all
new_extent <- c(-180, 180, -90, 90)

extent(banana) <- new_extent

#apply new extents to all files

tifs <- list.files(mapspam_dir, pattern = "\\.tif", full.names = TRUE)

adjust_extent <- \(this_filename){
  
  this_file <- basename(this_filename)
  message(paste("processing", which(tifs==this_file), "of", length(tifs)))
  this_raster <- rast(this_filename)
  ext(this_raster) <- new_extent
  writeRaster(x=this_raster, filename = file.path("/mnt/rdsi/raw_data/MAPSPAM/new-extents", this_file), overwrite = TRUE)
}

#run over mutliple cores to speed things up - pointer error but all files ran.
parallel::mclapply(X = tifs, FUN = adjust_extent, mc.cores = detectCores()-2)


```


Tidy global aquaculture production data

```{r}

aqua_prod_raw <- 
   read_csv(file.path(fishstat_dir, "global_aquaculture_production_1950_2020.csv")) %>% 
  clean_names() %>% 
  rename(country= country_name,
         species = asfis_species_name_2,
         area = fao_major_fishing_area_name,
         environment = environment_name) %>% 
   dplyr::select(-unit_name, -asfis_species_name_3, -fao_major_fishing_area_code) %>% 
   filter(!country %in% c("Totals - Tonnes - live weight", "FAO. 2022. Fishery and Aquaculture Statistics. Global aquaculture production 1950-2020 (FishStatJ). In: FAO Fisheries and Aquaculture Division [online]. Rome. Updated 2022. www.fao.org/fishery/statistics/software/fishstatj/en"))



flags <- aqua_prod_raw %>% 
  dplyr::select(-starts_with("x")) %>% 
  pivot_longer(names_to = "flag", values_to = "symbol", -c(country, species, area, environment, unit)) %>% 
  mutate(flag = case_when(symbol == "..." ~ "No data",
                           symbol == " " ~ "Data not separately available",
                           symbol == "-" ~ "Nil or zero",
                           symbol == "0 0" ~ "0<x<0.5",
                           symbol == "E" ~ "estimate",
                           is.na(symbol) ~ "Reported")) %>% 
  dplyr::select(-symbol)


#sorts country coding to deal with non-UTF characters that country code depends on
Encoding(aqua_prod_raw$country) <- "latin1" #deals with the non-UTF
aqua_prod_raw$country <- iconv(aqua_prod_raw$country, "latin1", "UTF-8",sub='')



aquaculture_prod <- 
  
  bind_cols(
    aqua_prod_raw %>%
      dplyr::select(-c(starts_with("s_"))) %>% 
      pivot_longer(names_to = "year", values_to = "value", cols = -c(country, species, area, environment, unit)) %>% 
      mutate(iso3c = countrycode(country, origin = "country.name", destination = "iso3c", warn = TRUE)) %>%
      mutate(iso3c = case_when(country == "Zanzibar" ~ "TZA",
                               country == "CuraÃ§ao" ~ "CUW",
                               country == "RÃ©union" ~ "REU", 
                               country == "TÃ¼rkiye" ~ "TUR",
                                TRUE ~ iso3c)) %>%
      mutate(year = gsub("x", "", year) %>% 
               as.numeric),
    
    flags %>% dplyr::select(flag)
  ) %>% 
  drop_na(iso3c)


# test <- aquaculture_prod %>% filter(is.na(iso3c)) %>% distinct(country)


saveRDS(object = aquaculture_prod, file = here("data", "tidy_data", "production-data", "aquaculture_production_tidy.rds"))


test <- aquaculture_prod %>% 
  filter(year == 2020)

test %>% filter(species == "Atlantic salmon") %>% pull(value) %>% sum() # 2721876

test %>% pull(value) %>% sum() # 122579080
2721876/122579080 # salmon aquaculture is ~2% of ALL production

# lets take out invertebrates and seaweeds

test2 <- test %>% filter(!str_detect(species, "seaweed|seaweeds|kelp|invertebrate|invertebrates|mussel|frog|oyster|crayfish|Abalone|abalone|clam|moss|turtle|Nori|worms|cockle|Roach|cucumber|urchin|squirts|Seaweed|weed|Tangle|scallop")) %>% pull(value) %>% sum() # 80765212


test %>% filter(!str_detect(species, "seaweed|seaweeds|kelp|moss|Nori|Roach|cucumber|squirts|Seaweed|weed|Tangle")) %>% pull(value) %>% sum()

2721876/80765212 # 0.03370109 - 3%? 

# lets check literature 
# SOFIA says 88 million tonnes of animal aquaculture - 63 relies on feed 
2721876/63000000 # based on that it would be ~4%

```

Unzip FAOSTAT Production data
```{r}
unzip(list.files(path=file.path(rdsi_dir, "raw_data/fao/FAOSTAT_2023"), pattern = "Production_Crops", full.names = TRUE), exdir = file.path(rdsi_dir, "raw_data/fao/FAOSTAT_2023"))

```

Tidy FAOSTAT Production data
```{r}

production_raw <- read_csv(file.path(rdsi_dir, "raw_data/fao/FAOSTAT_2023/Production_Crops_Livestock_E_All_Data_(Normalized).csv"))

production_flags <- read_csv(file.path(rdsi_dir, "raw_data/fao/FAOSTAT_2023/Production_Crops_Livestock_E_Flags.csv"))

production_raw <- production_raw |> 
  left_join(production_flags) |> 
  mutate(Description = if_else(is.na(Description), true = "Official data", false = Description)) |> 
  mutate(Sector = case_when(grepl("Milk|milk|Meat|meat|Fat|fat|Chicken|Buffaloes|Cattle|cattle|Camel|ffal|Pigs|abbit|worm|odent|urkey|oghurt|Wool|Sheep|Goat|Egg|egg|Asses|Beeh|Bees|Ducks|Cream|Geese|Horses|Honey|Lard|Mules|Birds|Skins|Butter|Cheese|Snail", Item) ~ "Livestock",
                            TRUE ~ "Crops"))

Encoding(production_raw$Area) <- "latin1" #deals with the non-UTF
production_raw$Area <- iconv(production_raw$Area, "latin1", "UTF-8",sub='')


#separate by sector
production_sector_list <- 
  production_raw  |> 
  clean_names()  |>  
  mutate(iso3c = countrycode(area, origin = "country.name", destination = "iso3c", warn = TRUE)) |> 
  group_split(sector)

#save
map(.x = production_sector_list, .f = function(this_element){
  saveRDS(object = this_element, file = sprintf(here("data/tidy_data/production-data/%s_production_tidy.rds"), tolower(unique(this_element$sector))))
})
  



```

Create a base raster
```{r}

base_raster <- rast()
values(base_raster) <- 1:ncell(base_raster)
base_raster_ea <- project(base_raster, equal_area_gp_proj)
res(base_raster_ea) <- 10000
values(base_raster_ea) <- 1:ncell(base_raster_ea) 

writeRaster(x = base_raster_ea, file = here("data/spatial/base_raster_gall_peters.tif"), overwrite=TRUE)

```

#FISHERIES DATA 


Pulling together the spatial industrial fisheries data and save to rdsi storage. 

```{r}

#THE v5 DATA

catch <- fread(file.path(watson_dir, "v5.0/Catch2015_2019.csv")) |> lazy_dt(immutable = FALSE) |> filter(IYear == 2017) |> as.data.table()

codes_cell <- fread(file.path(watson_dir, "v5.0/Codes_cells.csv")) |> lazy_dt(immutable = FALSE)

codes_country <- fread(file.path(watson_dir, "v5.0/Codes_country.csv"))|> lazy_dt(immutable = FALSE)

codes_gear <- fread(file.path(watson_dir, "v5.0/Codes_gear.csv")) |> lazy_dt(immutable = FALSE) |> select(Gear, FleetGearName, VBDesc) |> distinct() 

codes_taxa <- read.csv(file.path(watson_dir, "v5.0/Codes_taxa.csv")) |> lazy_dt(immutable = FALSE)


catch_joined <- catch |> 
  lazy_dt(immutable = FALSE) |> 
  left_join(codes_cell, by = "Cell") |>
  left_join(codes_country, by = c("CNumber" = "Cnumber")) |>
  left_join(codes_gear, by = c("Gear")) |>
  left_join(codes_taxa, by = "Taxonkey") |>
  rename(CountryName = `FAO name`) |> as.data.table()

fwrite(catch_joined, file.path(watson_dir, "v5.0/watson_2017_fisheries_catch.csv"))

```

#Filter FAO Species lists for forage fish spp

```{r}
fao_list <- read_csv(file.path(fao_dir, "species_lists/CL_FI_SPECIES_GROUPS.csv"))

unique(fao_list$ISSCAAP_Group)

forage_list <- fao_list |> filter(ISSCAAP_Group == "Herrings, sardines, anchovies" )

write_csv(forage_list, here("data/raw_data/fisheries/fao_forage_fish_spp_list.csv"))
```

#Prep list of forage fish used for fish oil/meal 

```{r}
 #145 unique species and species groups in the FAO data
forage_spp_fao <- read_csv(here("data/raw_data/fisheries/fao_forage_fish_spp_list.csv")) |> select(Name_en, Scientific_Name) |> distinct() |> rename(common_name = Name_en, sci_name = Scientific_Name) 

#bring in species highlighted in the SI of Froehlich et al 2018 Avoiding the ecological limits of forage fish. Nature Sustainability.
froehlich_spp <- read_csv(here("data/raw_data/fisheries/forage_fish_spp_froehlich_2018.csv")) %>%
  distinct(sci_name = Species) %>%
  mutate(common_name = sci2comm(sci_name)) ## ok so the species Rich is using from Halleys paper only represents 71% of total forage fish catch. I think i will use the 238 species for my data. 

froehlich_spp_df <- froehlich_spp %>%
  mutate(common_name = as.character(ifelse(common_name == "character(0)", NA, common_name))) %>%
  mutate(common_name = str_to_sentence(common_name)) %>%
  mutate(common_name = ifelse(common_name == "Na", NA, common_name))


#13 species in Kok et al - some not in the FAO data
forage_spp_koketal <- read_xlsx(here("data/tidy_data/allocation/embodied_fish_allocation.xlsx")) |> drop_na() |>  select(common_name = CommonName, sci_name) |> distinct() %>% drop_na()

#bind the two sources and save - 155 species considered in total
forage_spp_list <- bind_rows(forage_spp_fao, froehlich_spp_df, forage_spp_koketal) |> distinct() 

dups <- forage_spp_list %>%
  filter(duplicated(sci_name)) %>%
  pull(sci_name)

dup_spp <- forage_spp_list %>%
  filter(sci_name %in% dups) %>%
  filter(!is.na(common_name))

forage_spp_list_fin <- forage_spp_list %>%
  filter(!(sci_name %in% dups)) %>%
  rbind(dup_spp)

write_csv(forage_spp_list, here("data/raw_data/fisheries/forage_fish_list_final.csv"))

```


#Filter Watson spatialised catch data for forage fish species so it can be stored in the project. 

Data source: Watson v5.0 provided by request. v4.0 is publicly available through IMAS Research Data Portal https://metadata.imas.utas.edu.au/geonetwork/srv/eng/catalog.search#/metadata/5c4590d3-a45a-4d37-bf8b-ecd145cb356d

```{r}

#THE V5 DATA

catch <- read.csv((file.path(watson_dir, "v5.0/watson_2017_fisheries_catch.csv")))

forage_catch <- catch |> 
  # lazy_dt(immutable = FALSE) |> 
   dplyr::mutate(forage_id = ifelse(TaxonName %in% c(forage_spp_list$sci_name), 1, NA)) |> 
  mutate(total_catch = ReportedIND+IUUIND+ReportedNIND+IUUNIND, total_ind = ReportedIND+IUUIND, total_nind =ReportedNIND+IUUNIND) |>
  as_tibble()

test <- forage_catch %>% filter(forage_id == 1)

length(unique(test$TaxonName))

#31 million tonnes, represented by 186 species across industrial and non industrial sources. 31 million matches perfectly to Halley's paper. 
sum(test$total_catch) # 31551575
sum(test$total_ind) #27.1 mill is from industrial
sum(test$total_nind) #4.3 mill is from non-industrial
unique(test$TaxonName) 

tibble(Common_name = unique(test$CommonName), Species_binomial = unique(test$TaxonName) )

write.csv(forage_catch, file = file.path(watson_dir, "v5.0/watson_2017_catch_w_forage_id.csv"), row.names = FALSE)

```

